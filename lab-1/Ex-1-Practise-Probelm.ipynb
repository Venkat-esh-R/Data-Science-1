{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iZTaT_aIDoRP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Total jobs fetched: 95\n",
      "\n",
      "ðŸ“„ Preview of Job Listings:\n",
      "          Company Name                                  Job Role   Location  \\\n",
      "0            Machinify  Automation Engineer UI Quality Assurance  Palo Alto   \n",
      "1  Arbitrum Foundation              Developer Relations Engineer     Europe   \n",
      "2         Koala Health             Customer Experience Associate     Remote   \n",
      "3            CoinGecko       Human Resources Associate Mid level              \n",
      "4     Prophet Security                 Backend Software Engineer              \n",
      "\n",
      "                                       Features/Tags  \n",
      "0  ui, design, front-end, frontend, docker, softw...  \n",
      "1  developer, web3, cryptocurrency, ethereum, sec...  \n",
      "2  technical, support, web, voice, medical, healt...  \n",
      "3  cryptocurrency, hr, system, training, technica...  \n",
      "4  golang, infosec, software, security, engineer,...  \n",
      "\n",
      "ðŸ’¾ Data saved to 'remoteok_jobs.csv'\n"
     ]
    }
   ],
   "source": [
    "## ðŸ§ª Lab Task: Data Collection from RemoteOK\n",
    "\n",
    "#As a data scientist, the first step in any project is to collect relevant and structured data. In this exercise, your task is to extract job-related information from the RemoteOK job website: [https://remoteok.com/r](https://remoteok.com/r).\n",
    "\n",
    "### ðŸŽ¯ Objectives:\n",
    "#- Collect the following data fields for each job posting:\n",
    " # - **Company Name**\n",
    "  #- **Job Role**\n",
    "  #- **Location**\n",
    "  #- **Features or Tags** (e.g., technologies, benefits, job type)\n",
    "\n",
    "### ðŸ›  Instructions:\n",
    "#- Use Python along with libraries such as `requests`, `pandas`, and optionally `json` or `BeautifulSoup` if needed.\n",
    "#- Retrieve the job data from the RemoteOK API or web page.\n",
    "#- Parse the JSON or HTML response to extract the required fields.\n",
    "#- Store the collected data in a structured format such as **CSV** for future analysis.\n",
    "\n",
    "### ðŸ“¦ Output:\n",
    "#A CSV file (e.g., `remoteok_jobs.csv`) containing all extracted job listings with the specified fields.\n",
    "\n",
    "#> âœ… This dataset will serve as the foundation for further data analysis and machine learning tasks in upcoming lab exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
